{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time (s)         X         Y         Z      pca1      pca2   Time (s)  \\\n",
      "0  10.250332  0.012065 -0.550455  9.800024  0.197689  0.025060  10.247826   \n",
      "1  10.746557  0.020518 -0.545073  9.797954  0.206563  0.029507  10.749063   \n",
      "2  11.247795  0.035690 -0.493657  9.779238  0.226069  0.078197  11.250301   \n",
      "3  11.749034  0.132072 -0.061541  9.886638  0.364178  0.504528  11.751541   \n",
      "4  12.250274  0.720517  0.683281  9.873849  1.018785  1.189206  12.252781   \n",
      "\n",
      "          X         Y         Z      pca1      pca2   Time (s)         X  \\\n",
      "0 -0.000817 -0.000605 -0.001003 -0.005252  0.000219  10.247826 -0.007027   \n",
      "1 -0.000022  0.000382 -0.001239 -0.005561  0.001036  10.749063  0.000415   \n",
      "2  0.001961 -0.000264 -0.000147 -0.004455  0.003017  11.250301  0.008570   \n",
      "3  0.005399 -0.000180 -0.006632 -0.010975  0.006362  11.751541  0.109061   \n",
      "4  0.008621 -0.002708 -0.079796 -0.083859  0.008466  12.252781  0.650630   \n",
      "\n",
      "          Y         Z      pca1      pca2  label  \n",
      "0  0.010127  0.004482  0.059783  0.163531      0  \n",
      "1  0.015643  0.005915  0.067140  0.169246      0  \n",
      "2  0.063228 -0.020871  0.073942  0.215601      0  \n",
      "3  0.475696  0.093381  0.168371  0.634951      0  \n",
      "4  1.088782  0.073953  0.697701  1.256174      0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the filtered data folder\n",
    "data_folder = \"Data_Features\"  # Update this to the path where your filtered data is stored\n",
    "\n",
    "# Define a mapping from folder names to integer labels\n",
    "label_mapping = {\n",
    "    'auto': 0,\n",
    "    'bus': 1,\n",
    "    'fiets': 2,\n",
    "    'lopen': 3,\n",
    "    'metro': 4,\n",
    "    'paard': 5,\n",
    "    'tram': 6,\n",
    "    'trein': 7\n",
    "}\n",
    "\n",
    "# Initialize a list to hold the combined data\n",
    "combined_data_list = []\n",
    "\n",
    "# Iterate over each subfolder in the data_filtered folder\n",
    "for subfolder in os.listdir(data_folder):\n",
    "    subfolder_path = os.path.join(data_folder, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Read the accelerometer, gyroscope, and linear accelerometer CSV files\n",
    "        accelerometer_file = os.path.join(subfolder_path, 'Accelerometer_pca.csv')\n",
    "        gyroscope_file = os.path.join(subfolder_path, 'Gyroscope_pca.csv')\n",
    "        linear_accelerometer_file = os.path.join(subfolder_path, 'Linear Accelerometer_pca.csv')\n",
    "\n",
    "        \n",
    "        if os.path.exists(accelerometer_file) and os.path.exists(gyroscope_file) and os.path.exists(linear_accelerometer_file):\n",
    "            acc_data = pd.read_csv(accelerometer_file)\n",
    "            gyro_data = pd.read_csv(gyroscope_file)\n",
    "            lin_acc_data = pd.read_csv(linear_accelerometer_file)\n",
    "\n",
    "            #acc_data = acc_data.iloc[10:]\n",
    "            #gyro_data = gyro_data.iloc[10:]\n",
    "            #lin_acc_data = lin_acc_data.iloc[10:]          \n",
    "                     \n",
    "            # Reset index to align them properly for merging\n",
    "            acc_data.reset_index(drop=True, inplace=True)\n",
    "            gyro_data.reset_index(drop=True, inplace=True)\n",
    "            lin_acc_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            merged_data = pd.concat([acc_data, gyro_data, lin_acc_data], axis=1)\n",
    "\n",
    "            # Determine the label based on the folder name\n",
    "            label = next((label_mapping[key] for key in label_mapping if key in subfolder), None)\n",
    "            \n",
    "            if label is not None:\n",
    "                # Add the label column based on the folder name\n",
    "                merged_data['label'] = label\n",
    "            \n",
    "            # Append the merged data to the list\n",
    "            combined_data_list.append(merged_data)\n",
    "\n",
    "# Concatenate all the combined data into a single DataFrame\n",
    "combined_data = pd.concat(combined_data_list, ignore_index=True)\n",
    "\n",
    "# Check if data has been loaded and merged correctly\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5463\n",
       "2    5161\n",
       "6    3742\n",
       "0    3404\n",
       "4    2634\n",
       "3    2621\n",
       "7    2560\n",
       "1    2137\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 18019\n",
      "Validation set size: 2772\n",
      "Test set size: 6931\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (65%), validation (10%), and test sets (25%)\n",
    "train_data, test_data = train_test_split(combined_data, test_size=0.35, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.7143, random_state=42)  # 0.7143 * 0.35 â‰ˆ 0.25\n",
    "\n",
    "# Save the datasets to CSV files\n",
    "train_data.to_csv('Sets/pca/train_data_pca.csv', index=False)\n",
    "val_data.to_csv('Sets/pca/val_data_pca.csv', index=False)\n",
    "test_data.to_csv('Sets/pca/test_data_pca.csv', index=False)\n",
    "\n",
    "# Verify the split\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
